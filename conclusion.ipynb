{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los Resultados:\n",
    "##### Random Forest (RF Classifier):\n",
    "\n",
    "Precision (1): 0.77\n",
    "\n",
    "Recall (1): 0.57\n",
    "\n",
    "F1-score (1): 0.66\n",
    "\n",
    "ROC AUC: 0.7572\n",
    "\n",
    "El modelo RF tiene un recall bajo para la clase positiva (0.57), lo que indica que está dejando escapar muchos verdaderos positivos, es decir, está generando un número significativo de falsos negativos. Aunque la precisión es relativamente alta (0.77), este modelo podría no ser adecuado dado el alto costo de los falsos negativos.\n",
    "\n",
    "#####LightGBM:\n",
    "\n",
    "Precision (1): 0.79\n",
    "\n",
    "Recall (1): 0.63\n",
    "\n",
    "F1-score (1): 0.70\n",
    "\n",
    "ROC AUC: 0.7878\n",
    "\n",
    "LightGBM mejora tanto en recall (0.63) como en F1-score en comparación con Random Forest, lo que sugiere que es mejor en identificar correctamente los positivos. Sin embargo, sigue existiendo una cantidad significativa de falsos negativos. Su ROC AUC también es superior, lo que refleja un mejor equilibrio general entre las clases.\n",
    "\n",
    "##### CatBoost:\n",
    "\n",
    "Precision (1): 0.82\n",
    "\n",
    "Recall (1): 0.67\n",
    "\n",
    "F1-score (1): 0.74\n",
    "\n",
    "ROC AUC: 0.8126\n",
    "\n",
    "CatBoost ofrece el mejor rendimiento en términos de recall (0.67) y F1-score (0.74) para la clase positiva. Esto indica que captura más verdaderos positivos, reduciendo la cantidad de falsos negativos, lo cual es esencial dado el costo asociado. También tiene el ROC AUC más alto (0.8126), lo que sugiere que es el mejor modelo en términos de discriminación general entre clases.\n",
    "\n",
    "##### Red Neuronal:\n",
    "\n",
    "Precision (1): 0.67\n",
    "\n",
    "Recall (1): 0.57\n",
    "\n",
    "F1-score (1): 0.62\n",
    "\n",
    "ROC AUC: 0.7377\n",
    "\n",
    "La red neuronal muestra el peor rendimiento en recall (0.57) y F1-score (0.62) para la clase positiva, similar al Random Forest. Esto sugiere que también genera muchos falsos negativos, lo que podría ser problemático dada la situación.\n",
    "\n",
    "##### Selección de modelo:\n",
    "\n",
    "CatBoost parece ser el mejor modelo en este caso, ya que ofrece el mayor recall para la clase positiva (1) y el mejor equilibrio entre precisión y recall en términos de F1-score. Este modelo minimiza los falsos negativos, lo cual es crucial dada la importancia de evitar estos errores.\n",
    "\n",
    "LightGBM también es una buena opción, con un rendimiento cercano al de CatBoost. Si la interpretabilidad del modelo o el tiempo de entrenamiento son factores importantes, LightGBM podría ser preferible, aunque el costo de algunos falsos negativos adicionales tendría que ser evaluado.\n",
    "\n",
    "Random Forest y Red Neuronal no parecen ser las mejores opciones en este caso, dado que tienen un recall relativamente bajo para la clase positiva, lo que resultaría en un mayor número de falsos negativos.\n",
    "\n",
    "Futuras mejoras:\n",
    "\n",
    "Optimización de Recall:\n",
    "\n",
    "Dado que el costo de los falsos negativos es alto, podría ser útil ajustar aún más los hiperparámetros de los modelos CatBoost o LightGBM, o ajustar el umbral de decisión para favorecer un mayor recall.\n",
    "\n",
    "Ajuste del Umbral: \n",
    "\n",
    "Consideraré mover el umbral de clasificación hacia un valor menor (por ejemplo, 0.4 en lugar de 0.5) para aumentar el recall, aunque esto podría disminuir la precisión y aumentar los falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ¿Qué pasos del plan se realizaron y qué pasos se omitieron (explica por qué)?\n",
    "\n",
    "Prácticamente se realizaron todos los pasos descritos, pero necesité agregar otros para mejorar los modelos, por ejemplo, la creacion de nuevas características con  las fechas de los datasets\n",
    "\n",
    "#### - ¿Qué dificultades encontraste y cómo lograste resolverlas?\n",
    "\n",
    "La mayor fueron los tiempos de ejecucion al realizar un gridsearch, pero al obtener los mejores hiperparámetros pude avanzar de una mejor manera, además de que el preprocesamiento de los datos también fue un poco tardado, una vez superadas ambas etapas, fue mas sencillo realizar lo demás.\n",
    "\n",
    "#### - ¿Cuáles fueron algunos de los pasos clave para resolver la tarea?\n",
    "\n",
    "El preprocesamiento de los datos y el gridsearch, fueron las etapas claves, además del entendimiento del problema y la metrica seleccionada para elegir el mejor modelo\n",
    "\n",
    "#### - ¿Cuál es tu modelo final y qué nivel de calidad tiene?\n",
    "\n",
    "Fue un modelo de catboost con un recall de 0.67 y f1 de 0.74 para los valores positivos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
